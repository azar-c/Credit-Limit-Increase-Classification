{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff236803-2156-46e6-95a4-39f1a23b3cf7",
   "metadata": {
    "collapsed": false,
    "name": "Snowpark_ML"
   },
   "source": [
    "## Building a Predictive Model with Snowpark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326f977-d261-486a-803e-cae8734d8fa6",
   "metadata": {
    "collapsed": false,
    "name": "ImportingLibraries"
   },
   "source": [
    "## 1. Importing Required Libraries:\n",
    "\n",
    "Imports necessary libraries for data processing, machine learning, and Snowflake Snowpark operations. Suppresses warnings for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import of Libraries\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.metrics import accuracy_score\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.modeling.preprocessing import LabelEncoder\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.snowpark.functions import col, when, lit, floor, to_date, dayofweek, dayofmonth, month, hour\n",
    "from snowflake.snowpark.functions import col, when, lit, concat_ws, round as round_, log\n",
    "from snowflake.ml.modeling.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import io, joblib\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84263945-2a05-41a6-950d-bc14c6a20da6",
   "metadata": {
    "collapsed": false,
    "name": "ImportRegistry"
   },
   "source": [
    "## 2. Importing the Snowflake ML Registry\n",
    "\n",
    "Loads the Registry module, which enables storing, managing, and retrieving trained ML models in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee56e0-0c15-4430-bdc7-3e657e006603",
   "metadata": {
    "collapsed": false,
    "name": "GetActiveSession"
   },
   "source": [
    "## 3. Getting the Active Snowflake Session\n",
    "\n",
    "Establishes an active Snowflake session, which is required for executing Snowpark operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34783a-550f-494d-a4df-ba3778628897",
   "metadata": {
    "collapsed": false,
    "name": "Load_LoanData"
   },
   "source": [
    "## 4. Loading Credit Limit features from Snowflake Table\n",
    "\n",
    "Retrieves data from the CREDIT_LIMIT_MODEL_FEATURES table in Snowflake and loads it into a Snowpark DataFrame. The goal is to predict whetherthe credit limit for a customer can be increased or not. The show() function displays a sample of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"   |\"MARITAL_STATUS\"  |\"DAYS_ACT_OPEN\"  |\"AGE\"  |\"INCOME\"  |\"ANY_PREVIOUS_DEFAULT\"  |\"GENDER\"  |\"OCCUPATION\"  |\"LOAN_APPROVAL\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|John     |Single            |2058             |28     |3000      |False                   |M         |Engineer      |1                |\n",
      "|Mary     |Married           |2487             |34     |5000      |True                    |F         |Teacher       |0                |\n",
      "|David    |Single            |1577             |22     |2000      |False                   |M         |Doctor        |1                |\n",
      "|Sarah    |Married           |2896             |40     |8000      |False                   |F         |Engineer      |1                |\n",
      "|Mike     |Single            |2349             |32     |4000      |True                    |M         |Artist        |0                |\n",
      "|Emily    |Married           |2118             |29     |3500      |False                   |F         |Student       |1                |\n",
      "|Robert   |Single            |3400             |47     |6000      |True                    |M         |Engineer      |0                |\n",
      "|Jessica  |Married           |2314             |32     |4500      |False                   |F         |Manager       |1                |\n",
      "|Kevin    |Single            |2549             |35     |5500      |False                   |M         |Engineer      |1                |\n",
      "|Lisa     |Married           |1948             |27     |3200      |True                    |F         |NULL          |0                |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "credit_limit_df = session.table(\"CREDIT_LIMIT\")\n",
    "credit_limit_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf964da-5f67-4c0b-bdc3-2f041365d43e",
   "metadata": {
    "collapsed": false,
    "name": "Cat_continous_variables"
   },
   "source": [
    "## 5. Separating Categorical and Continuous Variables\n",
    "\n",
    "Group the categorical and continuous feature columns separately to facilitate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "cat_cols = ['GENDER', 'EMPLOYMENT_STATUS','HAS_AUTO_PAY_SETUP']\n",
    "cont_cols = ['AGE', 'ANNUAL_INCOME', 'YEARS_WITH_BANK', 'CREDIT_SCORE',\n",
    "             'CURRENT_CREDIT_LIMIT',\n",
    "             'UTILIZATION_RATE','MISSED_PAYMENTS_LAST_12_MONTHS',\n",
    "             'AVG_PAYMENT_DELAY_DAYS','DEBT_TO_INCOME_RATIO', 'MONTHLY_SPENDING']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79aa5ab-51a7-43e9-8159-933e8a5dd451",
   "metadata": {
    "collapsed": false,
    "name": "MissingValues"
   },
   "source": [
    "## 6. Handling Missing Values using Imputation\n",
    "\n",
    "Uses SimpleImputer to replace missing values in categorical columns with the most frequently occurring value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input value type doesn't match the target column data type, this replacement was skipped. Column Name: \"ANY_PREVIOUS_DEFAULT\", Type: StringType(16777216), Input Value: False, Type: <class 'bool'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"GENDER\"  |\"MARITAL_STATUS\"  |\"ANY_PREVIOUS_DEFAULT\"  |\"OCCUPATION\"  |\"NAME\"   |\"DAYS_ACT_OPEN\"  |\"AGE\"  |\"INCOME\"  |\"LOAN_APPROVAL\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|M         |Single            |false                   |Engineer      |John     |2058             |28     |3000      |1                |\n",
      "|F         |Married           |true                    |Teacher       |Mary     |2487             |34     |5000      |0                |\n",
      "|M         |Single            |false                   |Doctor        |David    |1577             |22     |2000      |1                |\n",
      "|F         |Married           |false                   |Engineer      |Sarah    |2896             |40     |8000      |1                |\n",
      "|M         |Single            |true                    |Artist        |Mike     |2349             |32     |4000      |0                |\n",
      "|F         |Married           |false                   |Student       |Emily    |2118             |29     |3500      |1                |\n",
      "|M         |Single            |true                    |Engineer      |Robert   |3400             |47     |6000      |0                |\n",
      "|F         |Married           |false                   |Manager       |Jessica  |2314             |32     |4500      |1                |\n",
      "|M         |Single            |false                   |Engineer      |Kevin    |2549             |35     |5500      |1                |\n",
      "|F         |Married           |true                    |Engineer      |Lisa     |1948             |27     |3200      |0                |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impute_cat = SimpleImputer(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    strategy=\"most_frequent\",\n",
    "    drop_input_cols=True,\n",
    ")\n",
    "\n",
    "credit_limit_df = impute_cat.fit(credit_limit_df).transform(credit_limit_df)\n",
    "credit_limit_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513a78c-c7da-4d6f-9e41-031e4c12ff29",
   "metadata": {
    "collapsed": false,
    "name": "LabelEncoding"
   },
   "source": [
    "## 7. Label Encoding Categorical Variables\n",
    "\n",
    "Converts categorical values into numerical representations using label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6e67f-faf2-4742-8b50-a01650f3a270",
   "metadata": {
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": [
    "output_cat_cols = ['GENDER_LE', 'EMPLOYMENT_STATUS_LE', 'HAS_AUTO_PAY_SETUP_LE']\n",
    "output_cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2a5fa-bc49-4a70-bd56-7f17327cbdad",
   "metadata": {
    "collapsed": false,
    "name": "cell46"
   },
   "source": [
    "## 8. Saving the Preprocessing Pipeline for Inference\n",
    "\n",
    "This step is needed to ensure consistency during inference, so the same transformations applied during training are reused later without retraining. It creates multiple label encoding steps for categorical columns, wraps them in a Snowpark Pipeline, fits and transforms the DataFrame, serializes the trained pipeline in memory, and uploads it to a Snowflake stage so it can be applied exactly the same way during future predictions.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf4da5-b0f1-4841-87f8-c68fc4633f60",
   "metadata": {
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "# Create a list of label encoding steps for each categorical column, \n",
    "pipeline_steps = [\n",
    "    (f\"{input_col}_LE\", LabelEncoder(input_cols=[input_col], output_cols=[output_col]))\n",
    "    for input_col, output_col in zip(cat_cols, output_cat_cols)\n",
    "]\n",
    "\n",
    "# Define the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=pipeline_steps)\n",
    "\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "transformed_df = preprocessing_pipeline.fit(credit_limit_df).transform(credit_limit_df)\n",
    "\n",
    "# Create an in-memory bytes buffer\n",
    "buffer = io.BytesIO()\n",
    "joblib.dump(preprocessing_pipeline, buffer)\n",
    "buffer.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1724b-be20-4744-afa2-396e9d7b8adc",
   "metadata": {
    "collapsed": false,
    "name": "cell47"
   },
   "source": [
    "## 9. Creating stage to store the joblib file created above for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa891d-c09a-4356-a5bc-e684a33cc04a",
   "metadata": {
    "language": "sql",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE STAGE ML_STG;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb42de-8331-40ec-a99f-b0923bd80417",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": [
    "# Upload the buffer to stage\n",
    "session.file.put_stream(\n",
    "buffer,\n",
    "\"@SNOWPARK_ML_DEMO.PUBLIC.ML_STG/preprocessing_pipeline.joblib\",\n",
    "overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb42ad-26fa-4ae1-8aef-c0e624e7953b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell3333"
   },
   "outputs": [],
   "source": [
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e8675-20a4-453f-a685-2505170808c0",
   "metadata": {
    "collapsed": false,
    "name": "DropName"
   },
   "source": [
    "## 10. Dropping Unused Columns\n",
    "\n",
    "Let us remove the Categorical Columns as we have encoded columns and CUSTOMER_ID column, as it is irrelevant for predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "transformed_df = transformed_df.drop(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2337a73-7e5e-4336-a77d-0651a4cb2af4",
   "metadata": {
    "collapsed": false,
    "name": "TrainTestSplit"
   },
   "source": [
    "## 11. Splitting Data into Training and Testing Sets\n",
    "\n",
    "Split the dataset into an 80% training set and a 20% test set, using a fixed seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = transformed_df.random_split(weights=[0.8, 0.2], seed=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e4448-0704-443c-944f-3ac227bb816c",
   "metadata": {
    "collapsed": false,
    "name": "RandomForestClassifier"
   },
   "source": [
    "## 12. Initializing a XGB Classifier and fitting it on training data\n",
    " \n",
    "Create a XGBClassifier model and define input features, target label (from the table), and the desired output column name. The model is then fitted against the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_cols = ['ELIGIBLE_FOR_INCREASE', 'CUSTOMER_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "# XGBClassifier model\n",
    "classifier = XGBClassifier(\n",
    "    input_cols=train_df.drop(unused_cols).columns,\n",
    "    label_cols=\"ELIGIBLE_FOR_INCREASE\",\n",
    "    output_cols=\"PRED_APPROVED\"\n",
    ")\n",
    "classifier.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549cfb2-ba7c-447e-a92a-6226f441af03",
   "metadata": {
    "collapsed": false,
    "name": "cell30"
   },
   "source": [
    "## 13. Compute Predictions against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2633ad-9408-40a2-be5a-50860eba4864",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "class_preds = classifier.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae9612-49e2-4e1d-8783-99df34f41db4",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2837f-002d-442e-8e8c-1c3617114699",
   "metadata": {
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "##  14. Compute Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda08d2-5069-4cc5-90fe-5b5e0695a2a1",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(df=class_preds, y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n",
    "                     y_pred_col_names=\"PRED_APPROVED\")\n",
    "auc = roc_auc_score(df=class_preds, y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n",
    "                    y_score_col_names=\"PRED_APPROVED\")\n",
    "f1 = f1_score(df=class_preds, y_true_col_names=\"ELIGIBLE_FOR_INCREASE\",\n",
    "              y_pred_col_names=\"PRED_APPROVED\")\n",
    "acc, auc, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ae8a2-01fc-48c3-8c5b-bd1c90fa6ddb",
   "metadata": {
    "collapsed": false,
    "name": "SetupRegistry"
   },
   "source": [
    "## 15. Setting up the Model Registry\n",
    "\n",
    "To use a trained machine learning model for predictions within Snowflake, you must first register it in the Snowflake Model Registry. This secure repository allows you to manage your models and their associated information within Snowflake, regardless of the model's origin or type. Once registered, running inference on the model becomes straightforward.\n",
    "The command below initializes a Snowflake ML model registry and prepares it to log the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "# Create a registry to log the model\n",
    "reg = Registry(session=session, database_name='SNOWPARK_ML_DEMO', \n",
    "               schema_name='PUBLIC' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982e9aa-cf0a-40bd-8a48-9e60527bfde7",
   "metadata": {
    "collapsed": false,
    "name": "LogModel"
   },
   "source": [
    "## 16. Logging the Model into Registry\n",
    "Store the trained model in the Snowflake model registry as version V1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "# Logging our model in the Registry\n",
    "\n",
    "# Define model name and version (use uppercase for name)\n",
    "model_name = \"CREDIT_LIMIT_MODEL\"\n",
    "model_version = 'V1'\n",
    "\n",
    "# Get sample input data to pass into the registry logging function\n",
    "X = train_df.drop(\"ELIGIBLE_FOR_INCREASE\")\n",
    "\n",
    "# Let's first log the very first model we trained\n",
    "model_ver = reg.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name=model_version,\n",
    "    model=classifier,\n",
    "    sample_input_data=X, # to provide the feature schema\n",
    ")\n",
    "\n",
    "model_ver.set_metric(\n",
    "        metric_name=\"ACC\",\n",
    "        value = acc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfcd5c-4728-45ce-9eb5-b2be1178c7cf",
   "metadata": {
    "collapsed": false,
    "name": "cell28"
   },
   "source": [
    "## 17. Feature Importance of the Tuned Model\n",
    "To identify which feature best affects our predictive variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0b930-ae5c-4cdd-ad7e-dd065bd5a7a6",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "# Step 1: Reference the model for feature importance extraction\n",
    "model = classifier.to_xgboost()\n",
    "\n",
    "# Step 2: Get feature importances from the best estimator\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Step 3: Create feature importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Features\": train_df.drop(unused_cols).columns,  \n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# Step 4: Convert to Snowpark DataFrame and write to Snowflake table\n",
    "importance_spdf = session.create_dataframe(importance_df)\n",
    "importance_spdf.write.mode(\"overwrite\").save_as_table(\"TBL_FEATURE_IMP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a62a8-8f7a-45ff-b4bb-92294840d002",
   "metadata": {
    "collapsed": false,
    "name": "cell41"
   },
   "source": [
    "## 18. Visualizing Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36158297-1cc8-4c46-a6f9-bd59f58740d3",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "importance_df[\"Features\"] = importance_df[\"Features\"].str.replace(r\"_LE$\", \"\", regex=True)\n",
    "\n",
    "# Create an interactive horizontal bar chart using Plotly Express\n",
    "fig = px.bar(\n",
    "    importance_df,\n",
    "    x=\"Importance\",\n",
    "    y=\"Features\",\n",
    "    orientation=\"h\",\n",
    "    color=\"Importance\",  # color by importance value\n",
    "    color_continuous_scale=\"Viridis\",# horizontal bars\n",
    "    title=\"Feature Importance\"\n",
    ")\n",
    "\n",
    "# Update layout to order features so the highest importance appears at the top\n",
    "fig.update_layout(yaxis={'categoryorder': 'total ascending'},height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a0901-1efc-4bbd-8593-1e4e6ed01a9e",
   "metadata": {
    "collapsed": false,
    "name": "ListModels"
   },
   "source": [
    "## 19. Listing Registered Models\n",
    "Display the models stored in the model registry.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>comment</th>\n",
       "      <th>owner</th>\n",
       "      <th>default_version_name</th>\n",
       "      <th>versions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-06 00:02:15.909000-08:00</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>None</td>\n",
       "      <td>ACCOUNTADMIN</td>\n",
       "      <td>V0</td>\n",
       "      <td>[\"V0\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on  name database_name schema_name comment  \\\n",
       "0 2024-03-06 00:02:15.909000-08:00  LOAN          LOAN  DEPARTMENT    None   \n",
       "\n",
       "          owner default_version_name versions  \n",
       "0  ACCOUNTADMIN                   V0   [\"V0\"]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List model\n",
    "reg.show_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa043b0-7564-4a22-b022-74b2d8100480",
   "metadata": {
    "collapsed": false,
    "name": "ListVersions"
   },
   "source": [
    "## 20. Listing Model Versions\n",
    "Retrieve and display the different versions of the CREDIT_LIMIT_MODEL.We have just the one version (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce110000-1111-2222-3333-ffffff000032",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>module_name</th>\n",
       "      <th>is_default_version</th>\n",
       "      <th>functions</th>\n",
       "      <th>metadata</th>\n",
       "      <th>user_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-06 00:02:15.942000-08:00</td>\n",
       "      <td>V0</td>\n",
       "      <td>None</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>true</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-06 00:22:13.240000-08:00</td>\n",
       "      <td>V1</td>\n",
       "      <td>None</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>false</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]</td>\n",
       "      <td>{\"metrics\": {\"accuracy\": 1.0}, \"snowpark_ml_sc...</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on name comment database_name schema_name  \\\n",
       "0 2024-03-06 00:02:15.942000-08:00   V0    None          LOAN  DEPARTMENT   \n",
       "1 2024-03-06 00:22:13.240000-08:00   V1    None          LOAN  DEPARTMENT   \n",
       "\n",
       "  module_name is_default_version  \\\n",
       "0        LOAN               true   \n",
       "1        LOAN              false   \n",
       "\n",
       "                                         functions  \\\n",
       "0  [\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]   \n",
       "1  [\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]   \n",
       "\n",
       "                                            metadata  \\\n",
       "0                                                 {}   \n",
       "1  {\"metrics\": {\"accuracy\": 1.0}, \"snowpark_ml_sc...   \n",
       "\n",
       "                                           user_data  \n",
       "0  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...  \n",
       "1  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_model(model_name).show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b4ff4-6d34-40b7-8e1a-62854b851c77",
   "metadata": {
    "collapsed": false,
    "name": "SetDefaultVersion"
   },
   "source": [
    "## 21. Setting a Default Model Version\n",
    "Assign V1 as the default model version for deployment and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000033",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "m = reg.get_model(model_name)\n",
    "m.default = 'V1'\n",
    "mv = m.default\n",
    "mv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32421097-bc55-4fbe-b3b3-3b231ee6c31c",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": [
    "## 22. Load the Inference Table into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cf33f-4860-4d7b-8890-af7eb7665df4",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "session = get_active_session()\n",
    "df = session.table(\"SNOWPARK_ML_DEMO.PUBLIC.CREDIT_LIMIT_MODEL_FEATURES_NEW\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c5abb-3620-47f1-9e8a-2932e8b056c1",
   "metadata": {
    "collapsed": false,
    "name": "cell42"
   },
   "source": [
    "## 23. Retrieve the saved Preprocessing Pipeline from Stage and apply it to the inference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f623dd-f20b-4cf4-82d1-9822871558f7",
   "metadata": {
    "language": "python",
    "name": "cell48"
   },
   "outputs": [],
   "source": [
    "# Load preprocessing pipeline from a file\n",
    "session.file.get('@SNOWPARK_ML_DEMO.PUBLIC.ML_STG/preprocessing_pipeline.joblib.gz', '/tmp')\n",
    "pipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n",
    "\n",
    "preprocessing_pipeline = joblib.load(pipeline_file)\n",
    "\n",
    "# Apply preprocessing\n",
    "testing_spdf = preprocessing_pipeline.fit(df).transform(df)\n",
    "testing_spdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858f557-6afd-46ce-9fad-19ec691d44d9",
   "metadata": {
    "collapsed": false,
    "name": "cell49"
   },
   "source": [
    "## 24. Run the Predictions on Inference Dataaet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785605b6-dd05-40a7-8611-05f8c9e9439b",
   "metadata": {
    "language": "python",
    "name": "cell50"
   },
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "results = mv.run(testing_spdf, function_name=\"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c11fc-89fe-4ae8-835a-cbf2e2224981",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "## 25. Displaying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac33c8-a796-4673-a25c-4234f7a6a007",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25976d6f-4555-4da5-8b38-5e2a333eb498",
   "metadata": {
    "collapsed": false,
    "name": "StoreData"
   },
   "source": [
    "## 26. Storing Inference data in a Snowflake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce110000-1111-2222-3333-ffffff000036",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": [
    "results.write.mode(\"overwrite\").save_as_table(\"CREDIT_LIMIT_APPROVAL_INFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9891c1cb-52b4-403c-9a85-1ff9c684ef5b",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM CREDIT_LIMIT_APPROVAL_INFERENCE;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "lastEditStatus": {
   "authorEmail": "sriramvel.m@cittabase.com",
   "authorId": "3825388797085",
   "authorName": "SRIRAMVEL",
   "lastEditTime": 1761045894951,
   "notebookId": "b3x4fw5rrnrh6l6lftfh",
   "sessionId": "04672cc6-313e-4926-a8cd-ecf123e71533"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
