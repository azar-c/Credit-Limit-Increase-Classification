{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "lastEditStatus": {
   "notebookId": "rpfipem3uh3vnhadgth7",
   "authorId": "2564583991407",
   "authorName": "KRISHNAN",
   "authorEmail": "krish.srinivasans@gmail.com",
   "sessionId": "60d2f90a-79f6-49a0-9182-8f4be1cd6bb5",
   "lastEditTime": 1754990319351
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff236803-2156-46e6-95a4-39f1a23b3cf7",
   "metadata": {
    "name": "Snowpark_ML",
    "collapsed": false
   },
   "source": "## Building a Predictive Model with Snowpark ML"
  },
  {
   "cell_type": "markdown",
   "id": "d326f977-d261-486a-803e-cae8734d8fa6",
   "metadata": {
    "name": "ImportingLibraries",
    "collapsed": false
   },
   "source": "## 1. Importing Required Libraries:\n\nImports necessary libraries for data processing, machine learning, and Snowflake Snowpark operations. Suppresses warnings for better readability"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "name": "cell1",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Import of Libraries\nimport warnings\n\nimport pandas as pd\nimport plotly.express as px\nfrom snowflake.ml.modeling.impute import SimpleImputer\nfrom snowflake.ml.modeling.metrics import accuracy_score\nfrom snowflake.ml.modeling.model_selection import GridSearchCV\nfrom snowflake.ml.modeling.preprocessing import LabelEncoder\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.modeling.model_selection import GridSearchCV\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import types as T\nfrom snowflake.snowpark.functions import col\nfrom snowflake.snowpark.functions import col, when, lit, floor, to_date, dayofweek, dayofmonth, month, hour\nfrom snowflake.snowpark.functions import col, when, lit, concat_ws, round as round_, log\nfrom snowflake.ml.modeling.metrics import accuracy_score, roc_auc_score, f1_score\n\nfrom snowflake.ml.modeling.pipeline import Pipeline\nimport io, joblib\n\nwarnings.simplefilter(action=\"ignore\", category=UserWarning)",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "markdown",
   "id": "84263945-2a05-41a6-950d-bc14c6a20da6",
   "metadata": {
    "name": "ImportRegistry",
    "collapsed": false
   },
   "source": "## 2. Importing the Snowflake ML Registry\n\nLoads the Registry module, which enables storing, managing, and retrieving trained ML models in Snowflake."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "name": "cell22",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry",
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "markdown",
   "id": "46ee56e0-0c15-4430-bdc7-3e657e006603",
   "metadata": {
    "name": "GetActiveSession",
    "collapsed": false
   },
   "source": "## 3. Getting the Active Snowflake Session\n\nEstablishes an active Snowflake session, which is required for executing Snowpark operations."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "name": "cell4",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()",
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "markdown",
   "id": "ab34783a-550f-494d-a4df-ba3778628897",
   "metadata": {
    "name": "Load_LoanData",
    "collapsed": false
   },
   "source": "## 4. Loading Credit Limit features from Snowflake Table\n\nRetrieves data from the CREDIT_LIMIT_MODEL_FEATURES table in Snowflake and loads it into a Snowpark DataFrame. The goal is to predict whetherthe credit limit for a customer can be increased or not. The show() function displays a sample of the dataset."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "name": "cell5",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"   |\"MARITAL_STATUS\"  |\"DAYS_ACT_OPEN\"  |\"AGE\"  |\"INCOME\"  |\"ANY_PREVIOUS_DEFAULT\"  |\"GENDER\"  |\"OCCUPATION\"  |\"LOAN_APPROVAL\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|John     |Single            |2058             |28     |3000      |False                   |M         |Engineer      |1                |\n",
      "|Mary     |Married           |2487             |34     |5000      |True                    |F         |Teacher       |0                |\n",
      "|David    |Single            |1577             |22     |2000      |False                   |M         |Doctor        |1                |\n",
      "|Sarah    |Married           |2896             |40     |8000      |False                   |F         |Engineer      |1                |\n",
      "|Mike     |Single            |2349             |32     |4000      |True                    |M         |Artist        |0                |\n",
      "|Emily    |Married           |2118             |29     |3500      |False                   |F         |Student       |1                |\n",
      "|Robert   |Single            |3400             |47     |6000      |True                    |M         |Engineer      |0                |\n",
      "|Jessica  |Married           |2314             |32     |4500      |False                   |F         |Manager       |1                |\n",
      "|Kevin    |Single            |2549             |35     |5500      |False                   |M         |Engineer      |1                |\n",
      "|Lisa     |Married           |1948             |27     |3200      |True                    |F         |NULL          |0                |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": "credit_limit_df = session.table(\"CREDIT_LIMIT_MODEL_FEATURES\")\ncredit_limit_df.show()",
   "id": "ce110000-1111-2222-3333-ffffff000004"
  },
  {
   "cell_type": "markdown",
   "id": "eaf964da-5f67-4c0b-bdc3-2f041365d43e",
   "metadata": {
    "name": "Cat_continous_variables",
    "collapsed": false
   },
   "source": "## 5. Separating Categorical and Continuous Variables\n\nGroup the categorical and continuous feature columns separately to facilitate preprocessing."
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "name": "cell8",
    "language": "python",
    "collapsed": false
   },
   "outputs": [],
   "source": "cat_cols = ['GENDER', 'EMPLOYMENT_STATUS','HAS_AUTO_PAY_SETUP']\ncont_cols = ['AGE', 'ANNUAL_INCOME', 'YEARS_WITH_BANK', 'CREDIT_SCORE',\n             'CURRENT_CREDIT_LIMIT',\n             'UTILIZATION_RATE','MISSED_PAYMENTS_LAST_12_MONTHS',\n             'AVG_PAYMENT_DELAY_DAYS','DEBT_TO_INCOME_RATIO', 'MONTHLY_SPENDING']",
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "markdown",
   "id": "d79aa5ab-51a7-43e9-8159-933e8a5dd451",
   "metadata": {
    "name": "MissingValues",
    "collapsed": false
   },
   "source": "## 6. Handling Missing Values using Imputation\n\nUses SimpleImputer to replace missing values in categorical columns with the most frequently occurring value."
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "name": "cell9",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input value type doesn't match the target column data type, this replacement was skipped. Column Name: \"ANY_PREVIOUS_DEFAULT\", Type: StringType(16777216), Input Value: False, Type: <class 'bool'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"GENDER\"  |\"MARITAL_STATUS\"  |\"ANY_PREVIOUS_DEFAULT\"  |\"OCCUPATION\"  |\"NAME\"   |\"DAYS_ACT_OPEN\"  |\"AGE\"  |\"INCOME\"  |\"LOAN_APPROVAL\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|M         |Single            |false                   |Engineer      |John     |2058             |28     |3000      |1                |\n",
      "|F         |Married           |true                    |Teacher       |Mary     |2487             |34     |5000      |0                |\n",
      "|M         |Single            |false                   |Doctor        |David    |1577             |22     |2000      |1                |\n",
      "|F         |Married           |false                   |Engineer      |Sarah    |2896             |40     |8000      |1                |\n",
      "|M         |Single            |true                    |Artist        |Mike     |2349             |32     |4000      |0                |\n",
      "|F         |Married           |false                   |Student       |Emily    |2118             |29     |3500      |1                |\n",
      "|M         |Single            |true                    |Engineer      |Robert   |3400             |47     |6000      |0                |\n",
      "|F         |Married           |false                   |Manager       |Jessica  |2314             |32     |4500      |1                |\n",
      "|M         |Single            |false                   |Engineer      |Kevin    |2549             |35     |5500      |1                |\n",
      "|F         |Married           |true                    |Engineer      |Lisa     |1948             |27     |3200      |0                |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": "impute_cat = SimpleImputer(\n    input_cols=cat_cols,\n    output_cols=cat_cols,\n    strategy=\"most_frequent\",\n    drop_input_cols=True,\n)\n\ncredit_limit_df = impute_cat.fit(credit_limit_df).transform(credit_limit_df)\ncredit_limit_df.show()",
   "id": "ce110000-1111-2222-3333-ffffff000008"
  },
  {
   "cell_type": "markdown",
   "id": "6513a78c-c7da-4d6f-9e41-031e4c12ff29",
   "metadata": {
    "name": "LabelEncoding",
    "collapsed": false
   },
   "source": "## 7. Label Encoding Categorical Variables\n\nConverts categorical values into numerical representations using label encoding."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "name": "cell10",
    "language": "python",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"OCCUPATION\"  |\"ANY_PREVIOUS_DEFAULT\"  |\"MARITAL_STATUS\"  |\"GENDER\"  |\"NAME\"   |\"DAYS_ACT_OPEN\"  |\"AGE\"  |\"INCOME\"  |\"LOAN_APPROVAL\"  |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2.0           |0.0                     |1.0               |1.0       |John     |2058             |28     |3000      |1                |\n",
      "|5.0           |1.0                     |0.0               |0.0       |Mary     |2487             |34     |5000      |0                |\n",
      "|1.0           |0.0                     |1.0               |1.0       |David    |1577             |22     |2000      |1                |\n",
      "|2.0           |0.0                     |0.0               |0.0       |Sarah    |2896             |40     |8000      |1                |\n",
      "|0.0           |1.0                     |1.0               |1.0       |Mike     |2349             |32     |4000      |0                |\n",
      "|4.0           |0.0                     |0.0               |0.0       |Emily    |2118             |29     |3500      |1                |\n",
      "|2.0           |1.0                     |1.0               |1.0       |Robert   |3400             |47     |6000      |0                |\n",
      "|3.0           |0.0                     |0.0               |0.0       |Jessica  |2314             |32     |4500      |1                |\n",
      "|2.0           |0.0                     |1.0               |1.0       |Kevin    |2549             |35     |5500      |1                |\n",
      "|2.0           |1.0                     |0.0               |0.0       |Lisa     |1948             |27     |3200      |0                |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": "# # Label Encoding\n# for i in cat_cols:\n#     LE = LabelEncoder(\n#     input_cols=i,\n#     output_cols=f\"{i}_ENCODED\",\n#     drop_input_cols=True)\n#     credit_limit_df = LE.fit(credit_limit_df).transform(credit_limit_df)\n#     # credit_limit_df.show() ",
   "id": "ce110000-1111-2222-3333-ffffff000009"
  },
  {
   "cell_type": "code",
   "id": "e0e6e67f-faf2-4742-8b50-a01650f3a270",
   "metadata": {
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": "output_cat_cols = ['GENDER_LE', 'EMPLOYMENT_STATUS_LE', 'HAS_AUTO_PAY_SETUP_LE']\noutput_cat_cols",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbb2a5fa-bc49-4a70-bd56-7f17327cbdad",
   "metadata": {
    "name": "cell46",
    "collapsed": false
   },
   "source": "## 8. Saving the Preprocessing Pipeline for Inference\n\nThis step is needed to ensure consistency during inference, so the same transformations applied during training are reused later without retraining. It creates multiple label encoding steps for categorical columns, wraps them in a Snowpark Pipeline, fits and transforms the DataFrame, serializes the trained pipeline in memory, and uploads it to a Snowflake stage so it can be applied exactly the same way during future predictions.\n "
  },
  {
   "cell_type": "code",
   "id": "6bbf4da5-b0f1-4841-87f8-c68fc4633f60",
   "metadata": {
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": "# Creating a pipeline\n# Create a list of label encoding steps for each categorical column, \npipeline_steps = [\n    (f\"{input_col}_LE\", LabelEncoder(input_cols=[input_col], output_cols=[output_col]))\n    for input_col, output_col in zip(cat_cols, output_cat_cols)\n]\n\n# Define the preprocessing pipeline\npreprocessing_pipeline = Pipeline(steps=pipeline_steps)\n\n\n# Fit and transform the DataFrame\ntransformed_df = preprocessing_pipeline.fit(credit_limit_df).transform(credit_limit_df)\n\n# Create an in-memory bytes buffer\nbuffer = io.BytesIO()\njoblib.dump(preprocessing_pipeline, buffer)\nbuffer.seek(0)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1b1724b-be20-4744-afa2-396e9d7b8adc",
   "metadata": {
    "name": "cell47",
    "collapsed": false
   },
   "source": "## 9. Creating stage to store the joblib file created above for future use"
  },
  {
   "cell_type": "code",
   "id": "80aa891d-c09a-4356-a5bc-e684a33cc04a",
   "metadata": {
    "language": "sql",
    "name": "cell44"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE ML_STG;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36cb42de-8331-40ec-a99f-b0923bd80417",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": "# Upload the buffer to stage\nsession.file.put_stream(\nbuffer,\n\"@SNOWPARK_ML_DEMO.PUBLIC.ML_STG/preprocessing_pipeline.joblib\",\noverwrite=True\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "16cb42ad-26fa-4ae1-8aef-c0e624e7953b",
   "metadata": {
    "language": "python",
    "name": "cell3333",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "transformed_df.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c2e8675-20a4-453f-a685-2505170808c0",
   "metadata": {
    "name": "DropName",
    "collapsed": false
   },
   "source": "## 10. Dropping Unused Columns\n\nLet us remove the Categorical Columns as we have encoded columns and CUSTOMER_ID column, as it is irrelevant for predictive modeling."
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "name": "cell11",
    "language": "python",
    "collapsed": false
   },
   "outputs": [],
   "source": "transformed_df = transformed_df.drop(cat_cols)\ntransformed_df = transformed_df.drop(\"CUSTOMER_ID\")",
   "id": "ce110000-1111-2222-3333-ffffff000010"
  },
  {
   "cell_type": "markdown",
   "id": "d2337a73-7e5e-4336-a77d-0651a4cb2af4",
   "metadata": {
    "name": "TrainTestSplit",
    "collapsed": false
   },
   "source": "## 11. Splitting Data into Training and Testing Sets\n\nSplit the dataset into an 80% training set and a 20% test set, using a fixed seed for reproducibility."
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "name": "cell12",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "train_df, test_df = transformed_df.random_split(weights=[0.8, 0.2], seed=8)",
   "id": "ce110000-1111-2222-3333-ffffff000011"
  },
  {
   "cell_type": "markdown",
   "id": "de2e4448-0704-443c-944f-3ac227bb816c",
   "metadata": {
    "name": "RandomForestClassifier",
    "collapsed": false
   },
   "source": "## 12. Initializing a XGB Classifier and fitting it on training data\n \nCreate a XGBClassifier model and define input features, target label (from the table), and the desired output column name. The model is then fitted against the training dataset"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "name": "cell13",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# XGBClassifier model\nclassifier = XGBClassifier(\n    input_cols=train_df.drop(\"ELIGIBLE_FOR_INCREASE\").columns,\n    label_cols=\"ELIGIBLE_FOR_INCREASE\",\n    output_cols=\"PRED_APPROVED\"\n)\nclassifier.fit(train_df)",
   "id": "ce110000-1111-2222-3333-ffffff000012"
  },
  {
   "cell_type": "markdown",
   "id": "0fa82c54-6933-4129-acae-83e14f568f54",
   "metadata": {
    "name": "cell29",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "6549cfb2-ba7c-447e-a92a-6226f441af03",
   "metadata": {
    "name": "cell30",
    "collapsed": false
   },
   "source": "## 13. Compute Predictions against test data"
  },
  {
   "cell_type": "code",
   "id": "eb2633ad-9408-40a2-be5a-50860eba4864",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "class_preds = classifier.predict(test_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfae9612-49e2-4e1d-8783-99df34f41db4",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "class_preds",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9a2837f-002d-442e-8e8c-1c3617114699",
   "metadata": {
    "name": "cell32",
    "collapsed": false
   },
   "source": "##  14. Compute Model Metrics"
  },
  {
   "cell_type": "code",
   "id": "cfda08d2-5069-4cc5-90fe-5b5e0695a2a1",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "acc = accuracy_score(df=class_preds, y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n                     y_pred_col_names=\"PRED_APPROVED\")\nauc = roc_auc_score(df=class_preds, y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n                    y_score_col_names=\"PRED_APPROVED\")\nf1 = f1_score(df=class_preds, y_true_col_names=\"ELIGIBLE_FOR_INCREASE\",\n              y_pred_col_names=\"PRED_APPROVED\")\nacc, auc, f1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fe6ae8a2-01fc-48c3-8c5b-bd1c90fa6ddb",
   "metadata": {
    "name": "SetupRegistry",
    "collapsed": false
   },
   "source": "## 15. Setting up the Model Registry\n\nTo use a trained machine learning model for predictions within Snowflake, you must first register it in the Snowflake Model Registry. This secure repository allows you to manage your models and their associated information within Snowflake, regardless of the model's origin or type. Once registered, running inference on the model becomes straightforward.\nThe command below initializes a Snowflake ML model registry and prepares it to log the trained model."
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "name": "cell15",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create a registry to log the model\nreg = Registry(session=session, database_name='SNOWPARK_ML_DEMO', \n               schema_name='PUBLIC' )",
   "id": "ce110000-1111-2222-3333-ffffff000014"
  },
  {
   "cell_type": "markdown",
   "id": "d982e9aa-cf0a-40bd-8a48-9e60527bfde7",
   "metadata": {
    "name": "LogModel",
    "collapsed": false
   },
   "source": "## 16. Logging the Model into Registry\nStore the trained model in the Snowflake model registry as version V1."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell17",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Logging our model in the Registry\n\n# Define model name and version (use uppercase for name)\nmodel_name = \"CREDIT_LIMIT_MODEL\"\nmodel_version = 'V1'\n\n# Get sample input data to pass into the registry logging function\nX = train_df.drop(\"ELIGIBLE_FOR_INCREASE\")\n\n# Let's first log the very first model we trained\nmodel_ver = reg.log_model(\n    model_name=model_name,\n    version_name=model_version,\n    model=classifier,\n    sample_input_data=X, # to provide the feature schema\n)\n\nmodel_ver.set_metric(\n        metric_name=\"ACC\",\n        value = acc,\n    )",
   "id": "ce110000-1111-2222-3333-ffffff000016"
  },
  {
   "cell_type": "markdown",
   "id": "3c451a1b-1d5a-4f9c-8051-05364df35193",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "## 17. Hyper parameter Tuning\nDifferent combinations of hyper parameters are validated using GridSearchCV and the best model will be used to run predictions on the test data.\n"
  },
  {
   "cell_type": "code",
   "id": "ec8e5d64-5d89-4119-9ca8-f6a5e4516a0f",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "param_grid = {\n   \"alpha\": [0.5, 0.7, 0.8],\n   \"n_estimators\": [100, 200],\n   \"max_depth\": [3, 5, 7],\n   \"learning_rate\": [0.05, 0.1],\n}\n\n# Hyper Parameter Tuning\ngrid_search = GridSearchCV(\nestimator=XGBClassifier(),\nparam_grid=param_grid,\ncv=5,\nscoring=\"accuracy\",\nn_jobs=1,  # Avoid parallel processing in Snowpark\ninput_cols=train_df.drop(\"ELIGIBLE_FOR_INCREASE\").columns,\nlabel_cols=\"ELIGIBLE_FOR_INCREASE\",\noutput_cols=\"PRED_APPROVED\"\n)\n\n# Fitting the Randomized Model\ngrid_search.fit(train_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "242f1a95-361b-4a0d-853c-f93fad153bb7",
   "metadata": {
    "language": "python",
    "name": "cell40",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Step 1: Convert Snowpark GridSearchCV to scikit-learn\nsklearn_grid = grid_search.to_sklearn()\n\n# Step 2: Get best estimator from sklearn GridSearchCV\nbest_model = sklearn_grid.best_estimator_\nbest_model",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45d2d1c3-9303-4dfe-aa82-3eaf4003e1fd",
   "metadata": {
    "name": "cell35",
    "collapsed": false
   },
   "source": "## 18. Run Predictions on the hyper parameter tuned model"
  },
  {
   "cell_type": "code",
   "id": "e9b22458-73eb-408f-81d2-002e584579f8",
   "metadata": {
    "language": "python",
    "name": "cell19",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Predictions on test data using the tuned model\ngrid_preds = grid_search.predict(test_df)\ngrid_preds.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5079da71-a074-43ea-9c08-0b3f36c2e42d",
   "metadata": {
    "name": "cell38",
    "collapsed": false
   },
   "source": "## 19. Examine the Evaluation Metrics"
  },
  {
   "cell_type": "code",
   "id": "efebc8a5-9889-4a8c-aab7-ff571e8a88e6",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "acc = accuracy_score(df=grid_preds, \n                     y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n                     y_pred_col_names=\"PRED_APPROVED\")\nauc = roc_auc_score(df=grid_preds, \n                    y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n                    y_score_col_names=\"PRED_APPROVED\")\nf1 = f1_score(df=grid_preds, \n              y_true_col_names=\"ELIGIBLE_FOR_INCREASE\",\n              y_pred_col_names=\"PRED_APPROVED\")\nacc, auc,f1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aacfcd5c-4728-45ce-9eb5-b2be1178c7cf",
   "metadata": {
    "name": "cell28",
    "collapsed": false
   },
   "source": "## 20. Feature Importance of the Tuned Model\nTo identify which feature best affects our predictive variable\n"
  },
  {
   "cell_type": "code",
   "id": "d9d0b930-ae5c-4cdd-ad7e-dd065bd5a7a6",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "# Step 1: Get feature importances from the best estimator\nfeature_importances = best_model.feature_importances_\n\n# Step 2: Create feature importance DataFrame\nimportance_df = pd.DataFrame({\n    \"Features\": train_df.drop([\"ELIGIBLE_FOR_INCREASE\"]).columns,  \n    \"Importance\": feature_importances\n}).sort_values(\"Importance\", ascending=False)\n\n# Step 3: Convert to Snowpark DataFrame and write to Snowflake table\nimportance_spdf = session.create_dataframe(importance_df)\nimportance_spdf.write.mode(\"overwrite\").save_as_table(\"TBL_FEATURE_IMP\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "704a62a8-8f7a-45ff-b4bb-92294840d002",
   "metadata": {
    "name": "cell41",
    "collapsed": false
   },
   "source": "## 21. Visualizing Feature Importance"
  },
  {
   "cell_type": "code",
   "id": "36158297-1cc8-4c46-a6f9-bd59f58740d3",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "importance_df[\"Features\"] = importance_df[\"Features\"].str.replace(r\"_LE$\", \"\", regex=True)\n\n# Create an interactive horizontal bar chart using Plotly Express\nfig = px.bar(\n    importance_df,\n    x=\"Importance\",\n    y=\"Features\",\n    orientation=\"h\",\n    color=\"Importance\",  # color by importance value\n    color_continuous_scale=\"Viridis\",# horizontal bars\n    title=\"Feature Importance\"\n)\n\n# Update layout to order features so the highest importance appears at the top\nfig.update_layout(yaxis={'categoryorder': 'total ascending'},height=500)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a34bc076-367b-4e1d-aa2b-deda73d31611",
   "metadata": {
    "name": "cell31",
    "collapsed": false
   },
   "source": "## 22. Logging the hyperparameter-tuned model as version V2 in the Model Registry."
  },
  {
   "cell_type": "code",
   "id": "8533c71f-e9e4-43d2-b528-22d475950211",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "# Logging our model in the Registry\n\n# Define model name and version (use uppercase for name)\nmodel_name = \"CREDIT_LIMIT_MODEL\"\nmodel_version = 'V2'\n\n# Get sample input data to pass into the registry logging function\nX = train_df.drop(\"ELIGIBLE_FOR_INCREASE\")\n\n# Let's first log the very first model we trained\nmodel_ver = reg.log_model(\n    model_name=model_name,\n    version_name=model_version,\n    model=grid_search,\n    sample_input_data=X, # to provide the feature schema\n)\n\nmodel_ver.set_metric(\n    metric_name=\"ACC\",\n    value = acc,\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "178a0901-1efc-4bbd-8593-1e4e6ed01a9e",
   "metadata": {
    "name": "ListModels",
    "collapsed": false
   },
   "source": "## 23. Listing Registered Models\nDisplay all models stored in the model registry.\n\n"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "name": "cell18",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>comment</th>\n",
       "      <th>owner</th>\n",
       "      <th>default_version_name</th>\n",
       "      <th>versions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-06 00:02:15.909000-08:00</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>None</td>\n",
       "      <td>ACCOUNTADMIN</td>\n",
       "      <td>V0</td>\n",
       "      <td>[\"V0\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on  name database_name schema_name comment  \\\n",
       "0 2024-03-06 00:02:15.909000-08:00  LOAN          LOAN  DEPARTMENT    None   \n",
       "\n",
       "          owner default_version_name versions  \n",
       "0  ACCOUNTADMIN                   V0   [\"V0\"]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List model\n",
    "reg.show_models()"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000017"
  },
  {
   "cell_type": "markdown",
   "id": "5fa043b0-7564-4a22-b022-74b2d8100480",
   "metadata": {
    "name": "ListVersions",
    "collapsed": false
   },
   "source": "## 24. Listing Model Versions\nRetrieve and display the different versions of the CREDIT_LIMIT_MODEL.We have just the one version (V1)"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "name": "cell33",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_on</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>database_name</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>module_name</th>\n",
       "      <th>is_default_version</th>\n",
       "      <th>functions</th>\n",
       "      <th>metadata</th>\n",
       "      <th>user_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-06 00:02:15.942000-08:00</td>\n",
       "      <td>V0</td>\n",
       "      <td>None</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>true</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-06 00:22:13.240000-08:00</td>\n",
       "      <td>V1</td>\n",
       "      <td>None</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>false</td>\n",
       "      <td>[\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]</td>\n",
       "      <td>{\"metrics\": {\"accuracy\": 1.0}, \"snowpark_ml_sc...</td>\n",
       "      <td>{\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_on name comment database_name schema_name  \\\n",
       "0 2024-03-06 00:02:15.942000-08:00   V0    None          LOAN  DEPARTMENT   \n",
       "1 2024-03-06 00:22:13.240000-08:00   V1    None          LOAN  DEPARTMENT   \n",
       "\n",
       "  module_name is_default_version  \\\n",
       "0        LOAN               true   \n",
       "1        LOAN              false   \n",
       "\n",
       "                                         functions  \\\n",
       "0  [\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]   \n",
       "1  [\"PREDICT_PROBA\",\"PREDICT\",\"PREDICT_LOG_PROBA\"]   \n",
       "\n",
       "                                            metadata  \\\n",
       "0                                                 {}   \n",
       "1  {\"metrics\": {\"accuracy\": 1.0}, \"snowpark_ml_sc...   \n",
       "\n",
       "                                           user_data  \n",
       "0  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...  \n",
       "1  {\"snowpark_ml_data\":{\"functions\":[{\"name\":\"PRE...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "reg.get_model(model_name).show_versions()",
   "id": "ce110000-1111-2222-3333-ffffff000032"
  },
  {
   "cell_type": "markdown",
   "id": "946b4ff4-6d34-40b7-8e1a-62854b851c77",
   "metadata": {
    "name": "SetDefaultVersion",
    "collapsed": false
   },
   "source": "## 25. Setting a Default Model Version\nAssign V2 as the default model version for deployment and predictions."
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "name": "cell34",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "m = reg.get_model(model_name)\nm.default = 'V2'\nmv = m.default\nmv",
   "id": "ce110000-1111-2222-3333-ffffff000033"
  },
  {
   "cell_type": "markdown",
   "id": "32421097-bc55-4fbe-b3b3-3b231ee6c31c",
   "metadata": {
    "name": "cell27",
    "collapsed": false
   },
   "source": "## 26. Load the Inference Table into memory"
  },
  {
   "cell_type": "code",
   "id": "5e8cf33f-4860-4d7b-8890-af7eb7665df4",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "session = get_active_session()\ndf = session.table(\"SNOWPARK_ML_DEMO.PUBLIC.CREDIT_LIMIT_MODEL_FEATURES_NEW\")\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c44c5abb-3620-47f1-9e8a-2932e8b056c1",
   "metadata": {
    "name": "cell42",
    "collapsed": false
   },
   "source": "## 27. Retrieve the saved Preprocessing Pipeline from Stage and apply it to the inference dataset"
  },
  {
   "cell_type": "code",
   "id": "91f623dd-f20b-4cf4-82d1-9822871558f7",
   "metadata": {
    "language": "python",
    "name": "cell48"
   },
   "outputs": [],
   "source": "# Load preprocessing pipeline from a file\nsession.file.get('@SNOWPARK_ML_DEMO.PUBLIC.ML_STG/preprocessing_pipeline.joblib.gz', '/tmp')\npipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n\npreprocessing_pipeline = joblib.load(pipeline_file)\n\n# Apply preprocessing\ntesting_spdf = preprocessing_pipeline.fit(df).transform(df)\ntesting_spdf.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e858f557-6afd-46ce-9fad-19ec691d44d9",
   "metadata": {
    "name": "cell49",
    "collapsed": false
   },
   "source": "## 28. Run the Predictions on Inference Dataaet"
  },
  {
   "cell_type": "code",
   "id": "785605b6-dd05-40a7-8611-05f8c9e9439b",
   "metadata": {
    "language": "python",
    "name": "cell50"
   },
   "outputs": [],
   "source": "# Perform prediction\nresults = mv.run(testing_spdf, function_name=\"predict\")\nresults.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b93ef77a-67bb-4278-8587-9e38dbdda0a8",
   "metadata": {
    "name": "cell51",
    "collapsed": false
   },
   "source": "## 29. Verify Model Metrics"
  },
  {
   "cell_type": "code",
   "id": "32eeb41d-9e0e-41d9-a570-503b51afc6d0",
   "metadata": {
    "language": "python",
    "name": "cell52"
   },
   "outputs": [],
   "source": "acc = accuracy_score(df=results, \n                     y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n                     y_pred_col_names=\"PRED_APPROVED\")\nauc = roc_auc_score(df=results, \n                    y_true_col_names=\"ELIGIBLE_FOR_INCREASE\", \n                    y_score_col_names=\"PRED_APPROVED\")\nf1 = f1_score(df=results, \n              y_true_col_names=\"ELIGIBLE_FOR_INCREASE\",\n              y_pred_col_names=\"PRED_APPROVED\")\nacc, auc,f1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25976d6f-4555-4da5-8b38-5e2a333eb498",
   "metadata": {
    "name": "StoreData",
    "collapsed": false
   },
   "source": "## 30. Storing Inference data in a Snowflake table"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "name": "cell37",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "results.write.mode(\"overwrite\").save_as_table(\"CREDIT_LIMIT_APPROVAL_INFERENCE\")",
   "id": "ce110000-1111-2222-3333-ffffff000036"
  },
  {
   "cell_type": "code",
   "id": "9891c1cb-52b4-403c-9a85-1ff9c684ef5b",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "SELECT * FROM CREDIT_LIMIT_APPROVAL_INFERENCE;",
   "execution_count": null
  }
 ]
}